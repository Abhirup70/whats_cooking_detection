{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhirup70/whats_cooking_detection/blob/main/What's_Cooking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DgkmrIC1RtEU"
      },
      "cell_type": "markdown",
      "source": [
        "# What's Cooking:- Building a Text Classifier\n",
        "> ![image.png](attachment:image.png)\n",
        "\n",
        "<br>This Kaggle competition asks us to predict the category of a dish's cuisine given a list of its ingredients.<b>This Notebook explores and analyses this dataset to build a Text Classifier</b>. It can also serve as a great starting point for learning how to explore, manipulate, transform and learn from textual data .\n",
        "<br><br> This Notebook is divided into the following sections:-\n",
        "* **A Date with Data**  : As they say, to know someone better you must meet him/her in person. In this section we will go on a date with data to explore and visualize it to gain insights\n",
        "* **Experiencing the Change** : As you and data fall in love, data experiences positive changes. In this section data is cleaned and pre-processed (which is a positive change) for model development.\n",
        "* **Exploring the Unknowns**: As the relationship between you and data goes on, you tend to explore and dig into what suits data the most. In this section we will explore which Feature Engineering technique for representing and converting text data gives the best results.\n",
        "* **The Final Decision** : Its time to build the Model\n",
        "\n",
        "<br> Let's Get the Party Started"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Y4GAP34ERtEg",
        "outputId": "d141b9e1-2c24-483b-c382-2833888d9f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "#Importing all the Libraries needed\n",
        "#Data Preprocessing\n",
        "from ipywidgets import interact\n",
        "#import unidecode\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import re\n",
        "#https://pypi.org/project/tqdm/ information on tqdm\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "#Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly\n",
        "from plotly import tools\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "import plotly.offline as offline\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "\n",
        "# Data Modeling\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models import FastText, Word2Vec\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold, cross_validate, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn import model_selection\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QqYAJxK1RtEk"
      },
      "cell_type": "code",
      "source": [
        "def random_colours(number_of_colors):\n",
        "    '''\n",
        "    Simple function for random colours generation.\n",
        "    Input:\n",
        "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
        "    Output:\n",
        "        Color in the following format: ['#E86DA4'] .\n",
        "    '''\n",
        "    colors = []\n",
        "    for i in range(number_of_colors):\n",
        "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
        "    return colors"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5afwmz8RtEl"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 1 :- A Date with Data  \n",
        "As the Experts always Say : Always Know your Data\n",
        "<br>I wouldn't say that knowing your data is the most difficult thing in data science, but it is time-consuming. Therefore, it's easy to overlook this initial step and jump too soon into the water.\n",
        "So I tried to learn how to swim before jumping into the water\n",
        "\n",
        "<br>In this section we will go on a date 'Data'. We will explore the data thoroughly , what its like, how it is distributed , what is the target , what affects the targets most ,etc"
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "3mWgoef3RtEn"
      },
      "cell_type": "code",
      "source": [
        "test = pd.read_json(\"/content/test.json\")\n",
        "train = pd.read_json(\"/content/train.json\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "W9IusxsvRtEn",
        "outputId": "5244e38e-8766-4525-8bb4-015cd95e3e1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 39774 entries, 0 to 39773\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   id           39774 non-null  int64 \n",
            " 1   cuisine      39774 non-null  object\n",
            " 2   ingredients  39774 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 932.3+ KB\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "c_leF9GKRtEp",
        "outputId": "c6e11e03-ec2e-4c19-c00c-637ebeb86cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9944 entries, 0 to 9943\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   id           9944 non-null   int64 \n",
            " 1   ingredients  9944 non-null   object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 155.5+ KB\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uylT-4TMRtEq",
        "outputId": "044194a9-0e52-4ad0-856b-5f2b14ec6977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id      cuisine                                        ingredients\n",
              "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
              "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
              "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
              "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
              "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfb7be9a-39f2-4711-b289-786471ce77a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cuisine</th>\n",
              "      <th>ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10259</td>\n",
              "      <td>greek</td>\n",
              "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25693</td>\n",
              "      <td>southern_us</td>\n",
              "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20130</td>\n",
              "      <td>filipino</td>\n",
              "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22213</td>\n",
              "      <td>indian</td>\n",
              "      <td>[water, vegetable oil, wheat, salt]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13162</td>\n",
              "      <td>indian</td>\n",
              "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfb7be9a-39f2-4711-b289-786471ce77a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfb7be9a-39f2-4711-b289-786471ce77a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfb7be9a-39f2-4711-b289-786471ce77a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bae27b87-bc1c-4176-b0be-2753ded3ab41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bae27b87-bc1c-4176-b0be-2753ded3ab41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bae27b87-bc1c-4176-b0be-2753ded3ab41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 39774,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14360,\n        \"min\": 0,\n        \"max\": 49717,\n        \"num_unique_values\": 39774,\n        \"samples\": [\n          7958,\n          36179,\n          8331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cuisine\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"greek\",\n          \"korean\",\n          \"japanese\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ingredients\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "NOR2SZAXRtEr",
        "outputId": "b2bc7ada-7139-44e5-ee65-e0856f8fd174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "train['cuisine'].unique()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['greek', 'southern_us', 'filipino', 'indian', 'jamaican',\n",
              "       'spanish', 'italian', 'mexican', 'chinese', 'british', 'thai',\n",
              "       'vietnamese', 'cajun_creole', 'brazilian', 'french', 'japanese',\n",
              "       'irish', 'korean', 'moroccan', 'russian'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "q5bw4Uo5RtEt"
      },
      "cell_type": "markdown",
      "source": [
        "The test and train data provided in this Kaggle competition are in json format. We have imported the data as a data frame object and the above lines of code show us the initial look of both samples.\n",
        "\n",
        "### So What can we Expect ?\n",
        "- There are 39774 unique recipies belonging to different cusines in the train set\n",
        "- There are 9944 unique recipies in the test set\n",
        "- Cuisine is the target variable\n",
        "- The Ingredients for every recipe is given as a list\n",
        "- Their are recipies from 20 different Cuisines. **This means that the problem at hand is a multi-class classification**"
      ]
    },
    {
      "metadata": {
        "id": "iSVgn3TWRtEt"
      },
      "cell_type": "markdown",
      "source": [
        "Creating a plot to See the Distribution of Different type of Cuisines in the Train Data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fjTbJneqRtEu"
      },
      "cell_type": "code",
      "source": [
        "train['cuisine'].value_counts().plot.bar(color=random_colours(20),figsize=(16,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4F2ce53SRtEu"
      },
      "cell_type": "markdown",
      "source": [
        "From the plot of label distribution, we observe that the most common category in our sample is the Italian cuisine, followed by the Mexican. The least represented cuisines are the Irish, Jamaican, Russian and Brazilian - counting for only 6% of our training sample of recipes."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iqGvHEYgRtEv"
      },
      "cell_type": "code",
      "source": [
        "# Taking Out all the ingredients in the dataset and storing in a list\n",
        "raw_ingredients = [ing for ingredients in train['ingredients'] for ing in ingredients]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wu1JcSp1RtEv"
      },
      "cell_type": "markdown",
      "source": [
        "**Time To Look At The Ingredients and their Distribution among different Cuisines**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "P_mqoM-oRtEv"
      },
      "cell_type": "code",
      "source": [
        "print('Maximum Number of Ingredients in a Dish: ',train['ingredients'].str.len().max())\n",
        "print('Minimum Number of Ingredients in a Dish: ',train['ingredients'].str.len().min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViDclXGKRtEw"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating A Feature that counts the Number Of Ingredients used in a given Recipe**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JmPvGXiyRtEw"
      },
      "cell_type": "code",
      "source": [
        "#no of Ingredients\n",
        "train['num_ing'] = train['ingredients'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Z5zwZoxDRtEw"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "sns.distplot(train['num_ing'],kde =False ,bins=60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cA3Tr9__RtEx"
      },
      "cell_type": "markdown",
      "source": [
        "The distribution of recipe length is right-skewed as we can see from the histogram above."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZxLqSEFXRtEz"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "sns.countplot(x='num_ing',data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F17mtgOZRtEz"
      },
      "cell_type": "markdown",
      "source": [
        "We Can See recipes with only one ingredient which is very small and recipes with more than 50 ingredients which is insanely High. These are outliers and could get our model confused , unfortunately there some examples with single ingredient and high ingredients in test set as well"
      ]
    },
    {
      "metadata": {
        "id": "GAIHbReXRtE0"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's Take a closer look at the extremes"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lvdHTduJRtE0"
      },
      "cell_type": "code",
      "source": [
        "longrecip = train[train['num_ing'] > 30]\n",
        "print(len(longrecip))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RsMi7qHIRtE0"
      },
      "cell_type": "markdown",
      "source": [
        "It seems that 40 recipes consist of more than 30 ingredients!\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "P39qDz60RtE1"
      },
      "cell_type": "code",
      "source": [
        "longrecip['cuisine'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSXArlVWRtE1"
      },
      "cell_type": "markdown",
      "source": [
        "**Explore the ingredients in the longest recipe in our training set**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "718H6VKeRtE1"
      },
      "cell_type": "code",
      "source": [
        "print(longrecip[longrecip['num_ing'] == 65]['ingredients'].values)\n",
        "print('Cuisine :-',longrecip[longrecip['num_ing'] == 65]['cuisine'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZ59WBp6RtE1"
      },
      "cell_type": "markdown",
      "source": [
        "The longest recipe in our sample is part of the Italian cuisine. However, Italian cuisine is often associated with simple recipes. Also 65 ingredients can be considered too many for any recipe.So, My guess is that the case is more about wrong data in our sample rather than anything else"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Sd-1arsgRtE2"
      },
      "cell_type": "code",
      "source": [
        "shortrecip = train[train['num_ing']<=2]\n",
        "print(len(shortrecip))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tNMcyDNRtE2"
      },
      "cell_type": "markdown",
      "source": [
        "**It seems that 215 recipes consist of less than or equal to 2 ingredients**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OXlB0YI-RtE2"
      },
      "cell_type": "code",
      "source": [
        "shortrecip['cuisine'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "auChOKKSRtE4"
      },
      "cell_type": "code",
      "source": [
        "train[train['num_ing'] <= 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3nQ1_zWRtE4"
      },
      "cell_type": "markdown",
      "source": [
        "But, are all ingredients valid? For example, do ingredients consisting of less than 2 characters make sense?"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PZmao3jkRtE4"
      },
      "cell_type": "code",
      "source": [
        "[ingredient for ingredient in raw_ingredients if len(ingredient) <= 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4jXw7badRtE5"
      },
      "cell_type": "markdown",
      "source": [
        "Apparently Not all the Words make sense , We will keep this in mind"
      ]
    },
    {
      "metadata": {
        "id": "fnyBnlE1RtE5"
      },
      "cell_type": "markdown",
      "source": [
        "Explore recipe length distribution in each cuisine"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "g9KIzmhaRtE5"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.boxplot(x='cuisine',y='num_ing',data=train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oB2GPXGwRtE6"
      },
      "cell_type": "markdown",
      "source": [
        "From the box plots of recipe length distributions, we can make several observations:\n",
        "\n",
        "- The Moroccan cuisine seems to have the longest recipes on average compared to all the rest cuisines in our sample\n",
        "- We observe the opposite phenomenon for the Irish, British, French and Southern_us cuisine\n",
        "- There exist outliers in all cuisines\n",
        "- Recipes part of the European cuisine tend to be with average length or shorter compared to the rest of the sample.\n"
      ]
    },
    {
      "metadata": {
        "id": "7wirF2LwRtFG"
      },
      "cell_type": "markdown",
      "source": [
        "### Special Characters"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hZQqTYqsRtFG"
      },
      "cell_type": "code",
      "source": [
        "' '.join(sorted([char for char in set(' '.join(raw_ingredients)) if re.findall('[^A-Za-z]', char)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DErs6pSLRtFG"
      },
      "cell_type": "markdown",
      "source": [
        "The Special Characters have come from ingredients from a specific company or from ingredients which come in packaging:\n",
        "- \"Bertolli® Alfredo Sauce\"\n",
        "- \"Progresso™ Chicken Broth\"\n",
        "- \"green bell pepper, slice\"\n",
        "- \"half & half\"\n",
        "- \"asafetida (powder)\"\n",
        "- \"Spring! Water\""
      ]
    },
    {
      "metadata": {
        "id": "dYdq7wugRtFH"
      },
      "cell_type": "markdown",
      "source": [
        "### Upper Cases\n",
        "Since Company names and Region Names are used in ingredients it may have been written in uppercase so checking for that"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Do9VptNoRtFI"
      },
      "cell_type": "code",
      "source": [
        "list(set([ingredient for ingredient in raw_ingredients if re.findall('[A-Z]+', ingredient)]))[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZ97e7eXRtFI"
      },
      "cell_type": "markdown",
      "source": [
        " ### Apostrophes"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "H_NYnVvzRtFI"
      },
      "cell_type": "code",
      "source": [
        "list(set([ingredient for ingredient in raw_ingredients if '’' in ingredient]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMsj6-S_RtFJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyphens ( - )\n",
        "We will Replace (-)  with null string (\"\") later on if found"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "eZvJuPflRtFK"
      },
      "cell_type": "code",
      "source": [
        "list(set([ingredient for ingredient in raw_ingredients if re.findall('-', ingredient)]))[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fJdfLy50RtFK"
      },
      "cell_type": "markdown",
      "source": [
        "### Numbers"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2qA6uLl2RtFK"
      },
      "cell_type": "code",
      "source": [
        "temp_ing = list(set([ingredient for ingredient in raw_ingredients if re.findall('[0-9]', ingredient)]))\n",
        "temp_ing[:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "N1vrUseYRtFL"
      },
      "cell_type": "code",
      "source": [
        "len(temp_ing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MzrV4mxGRtFL"
      },
      "cell_type": "markdown",
      "source": [
        "**Numbers show quantity or density. Quantities can be a factor of identifying the cuisine , but the number of ingredients containing numbers is just 40 so it will be better to remove the numbers**"
      ]
    },
    {
      "metadata": {
        "id": "tfQQxGT5RtFL"
      },
      "cell_type": "markdown",
      "source": [
        "### Units"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "at98LcjURtFN"
      },
      "cell_type": "code",
      "source": [
        "units = ['inch', 'oz', 'lb', 'ounc', '%'] # ounc is a misspelling of ounce?\n",
        "\n",
        "@interact(unit=units)\n",
        "def f(unit):\n",
        "    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if unit in ingredient], columns=['ingredient'])\n",
        "    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ynWzfg7fRtFN"
      },
      "cell_type": "markdown",
      "source": [
        "We will remove all the units from the ingredients as it will not be helpful for the model"
      ]
    },
    {
      "metadata": {
        "id": "vQiSANHZRtFO"
      },
      "cell_type": "markdown",
      "source": [
        "### Regions\n",
        "We will explore whether or not the name of the region is present in the name of ingredients , For Eg:- Greek Yogurt. If found this will help the model and an unigram model will perform better"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "qm5j_mLJRtFP"
      },
      "cell_type": "code",
      "source": [
        "keywords = ['american', 'greek', 'filipino', 'indian', 'jamaican', 'spanish', 'italian', 'mexican', 'chinese', 'thai',\n",
        "    'vietnamese', 'cajun', 'creole', 'french', 'japanese', 'irish', 'korean', 'moroccan', 'russian',\n",
        "]\n",
        "d ={}\n",
        "for k in keywords:\n",
        "    temp = [ingredient for ingredient in raw_ingredients if k in ingredient]\n",
        "    d[k] = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0eqgllQ1RtFP"
      },
      "cell_type": "code",
      "source": [
        "d['american']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ReVjPI2iRtFR"
      },
      "cell_type": "markdown",
      "source": [
        "So we can see there are region names present , we will keep this in our mind"
      ]
    },
    {
      "metadata": {
        "id": "qC8DWq5gRtFS"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploring Most Common Ingredients in the whole dataset\n",
        "We make use of counter function from the collections module here . Help on this function can be found from here :\n",
        "https://www.youtube.com/watch?v=cDw3ppRKAck"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Fz1AKfsARtFS"
      },
      "cell_type": "code",
      "source": [
        "top = Counter([item for sublist in train['ingredients'] for item in sublist])\n",
        "print(top.most_common(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rP6fmFaGRtFT"
      },
      "cell_type": "code",
      "source": [
        "temp = pd.DataFrame(top.most_common(20))\n",
        "temp.columns = ['ingredients','total_count']\n",
        "plt.figure(figsize=(7,9))\n",
        "sns.barplot(x='total_count',y='ingredients',data=temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PL8znusRtFT"
      },
      "cell_type": "markdown",
      "source": [
        "It seems that salt is the most commonly used ingredient which is not surprising at all! We also find water, onions, garlic and olive oil - not so surprising also .\n",
        "**Salt is such a common ingredient that we expect it to have poor predictive power in recognizing the type of cuisine**\n",
        "We will remove salt and some other common ingredients from the mix to make our model do better"
      ]
    },
    {
      "metadata": {
        "id": "6m0qK9SERtFT"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploring how many different ingredients can be found in each"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "nr94l_scRtFU"
      },
      "cell_type": "code",
      "source": [
        "labels = ['greek', 'southern_us', 'filipino', 'indian', 'jamaican',\n",
        "       'spanish', 'italian', 'mexican', 'chinese', 'british', 'thai',\n",
        "       'vietnamese', 'cajun_creole', 'brazilian', 'french', 'japanese',\n",
        "       'irish', 'korean', 'moroccan', 'russian']\n",
        "templist=[]\n",
        "for cus in labels:\n",
        "    lisofing=[]\n",
        "    for lis in train[train['cuisine'] == cus]['ingredients']:\n",
        "        for ing in lis:\n",
        "            lisofing.append(ing)\n",
        "    templist.append([cus,len(list(set(lisofing)))])\n",
        "Unique_ing = pd.DataFrame(templist,columns=['cuisine','unique_ing']).sort_values(by='unique_ing',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "qhL4Lwn2RtFV"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.barplot(x='cuisine',y='unique_ing',data=Unique_ing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cIMhSr_rRtFV"
      },
      "cell_type": "markdown",
      "source": [
        "From the above bar chart, we can see that it is not necessary that cuisines with more instances in the training sample should be associated with more ingredients representing them. It turns out that the French cuisine which is 6,65% of the training sample has more variability in ingredients than the Indian cuisine (this observation is unexpected since Indians use many spices in their recipes"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "smMxRSjERtFV"
      },
      "cell_type": "code",
      "source": [
        "def cuisine_unique(cuisine,numingr,raw_ingredients):\n",
        "    '''\n",
        "    Input:\n",
        "        cuisine - cuisine category (ex. 'brazilian');\n",
        "        numingr - how many specific ingredients do you want to see in the final result;\n",
        "        allingredients - list  for item in train_data[train_data.cuisine == cuisine]['ingredients']:\n",
        "    Output:\n",
        "        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n",
        "\n",
        "    '''\n",
        "    allother = []\n",
        "    for item in train[train.cuisine != cuisine]['ingredients']:\n",
        "        for ingr in item:\n",
        "            allother .append(ingr)\n",
        "    allother  = list(set(allother ))\n",
        "\n",
        "    specificnonly = [x for x in raw_ingredients if x not in allother]\n",
        "\n",
        "    mycounter = Counter()\n",
        "\n",
        "    for item in train[train.cuisine == cuisine]['ingredients']:\n",
        "        for ingr in item:\n",
        "            mycounter[ingr] += 1\n",
        "    keep = list(specificnonly)\n",
        "\n",
        "    for word in list(mycounter):\n",
        "        if word not in keep:\n",
        "            del mycounter[word]\n",
        "\n",
        "    cuisinespec = pd.DataFrame(mycounter.most_common(numingr), columns = ['ingredient','count'])\n",
        "\n",
        "    return cuisinespec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4dno6TKURtFW"
      },
      "cell_type": "code",
      "source": [
        "cuisinespec= cuisine_unique('mexican', 10, raw_ingredients)\n",
        "print(\"The top 10 unique ingredients in Mexican cuisine are:\")\n",
        "cuisinespec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bMsW9VrfRtFW"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 2 :- Experiencing the Change"
      ]
    },
    {
      "metadata": {
        "id": "EW4f9wgbRtFX"
      },
      "cell_type": "markdown",
      "source": [
        "In this section we will :-\n",
        "* Remove outliers\n",
        "* convert to lowercase\n",
        "* remove hyphen\n",
        "* remove numbers\n",
        "* remove words which consist of less than 2 characters\n",
        "* remove units\n",
        "* remove accents\n",
        "* lemmatize"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QjmJr9zLRtFX"
      },
      "cell_type": "code",
      "source": [
        "#Removing Outliers Values that were irrevelant to model\n",
        "train = train[train['num_ing'] > 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0uAKodP5RtFX"
      },
      "cell_type": "code",
      "source": [
        "train = train[train['num_ing']<60]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OatoJleNRtFY"
      },
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bkx-lZGURtFY"
      },
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess(ingredients):\n",
        "    ingredients_text = ' '.join(ingredients)\n",
        "    ingredients_text = ingredients_text.lower() #Lower - Casing\n",
        "    ingredients_text = ingredients_text.replace('-', ' ') # Removing Hyphen\n",
        "    words = []\n",
        "    for word in ingredients_text.split():\n",
        "        word = re.sub(\"[0-9]\",\" \",word) #removing numbers,punctuations and special characters\n",
        "        word = re.sub((r'\\b(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\b'), ' ', word) # Removing Units\n",
        "        if len(word) <= 2: continue # Removing words with less than two characters\n",
        "        word = unidecode.unidecode(word) #Removing accents\n",
        "        word = lemmatizer.lemmatize(word) #Lemmatize\n",
        "        if len(word) > 0: words.append(word)\n",
        "    return ' '.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_6vQSckRtFZ"
      },
      "cell_type": "markdown",
      "source": [
        "https://pypi.org/project/Unidecode/\n",
        "Information about unidecode can be read from here"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "YO0Kz_KNRtFZ"
      },
      "cell_type": "code",
      "source": [
        "#Checking if our function works\n",
        "for ingredient, expected in [\n",
        "    ('Eggs', 'egg'),\n",
        "    ('all-purpose flour', 'all purpose flour'),\n",
        "    ('purée', 'puree'),\n",
        "    ('1% low-fat milk', 'low fat milk'),\n",
        "    ('half & half', 'half half'),\n",
        "    ('safetida (powder)', 'safetida (powder)')\n",
        "]:\n",
        "    actual = preprocess([ingredient])\n",
        "    assert actual == expected, f'\"{expected}\" is excpected but got \"{actual}\"'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "eZ9noymBRtFc"
      },
      "cell_type": "code",
      "source": [
        "train['x'] = train['ingredients'].progress_apply(preprocess)\n",
        "test['x'] = test['ingredients'].progress_apply(preprocess)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_LOQoDBfRtFd"
      },
      "cell_type": "markdown",
      "source": [
        "Now That we have completed cleaning and changed our data for the better its time to chose the method which we will use to tranform text into numbers"
      ]
    },
    {
      "metadata": {
        "id": "B8d3skcxRtFd"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter :- Exploring the Unknowns"
      ]
    },
    {
      "metadata": {
        "id": "Gtlk924ORtFd"
      },
      "cell_type": "markdown",
      "source": [
        "We need to convert ingredeints to numeric values so that computers can do mathematical operations. My question was what the best representation is for this dataset.\n",
        "\n",
        "I have compared representations below.\n",
        "\n",
        "* CountVectorizer\n",
        "* TfidfVectorizer\n",
        "* TfidfVectorizer + SVD\n",
        "* Word2Vec\n",
        "* fastText"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Wy1alZiPRtFe"
      },
      "cell_type": "code",
      "source": [
        "def apply_word2vec(sentences):\n",
        "    vectorizer = Word2Vec(\n",
        "        sentences,\n",
        "        size=500,\n",
        "        window=20,\n",
        "        min_count=3,\n",
        "        sg=1,\n",
        "        iter=20\n",
        "    )\n",
        "\n",
        "    def to_vector(sentence):\n",
        "        words = [word for word in sentence if word in vectorizer.wv.vocab]\n",
        "        if words:\n",
        "            return np.mean(vectorizer[words], axis=0)\n",
        "        else:\n",
        "            return np.zeros(500)\n",
        "\n",
        "    return np.array([to_vector(sentence) for sentence in sentences])\n",
        "\n",
        "def apply_fasttext(sentences):\n",
        "    vectorizer = FastText(\n",
        "        size=500,\n",
        "        window=20,\n",
        "        min_count=3,\n",
        "        sg=1,\n",
        "        iter=20\n",
        "        )\n",
        "    vectorizer.build_vocab(sentences)\n",
        "    vectorizer.train(sentences, total_examples=vectorizer.corpus_count, epochs=vectorizer.iter)\n",
        "\n",
        "    def to_vector(sentence):\n",
        "        words = [word for word in sentence if word in vectorizer.wv.vocab]\n",
        "        if words:\n",
        "            return np.mean(vectorizer.wv[words], axis=0)\n",
        "        else:\n",
        "            return np.zeros(500)\n",
        "\n",
        "    return np.array([to_vector(sentence) for sentence in sentences])\n",
        "\n",
        "def train_model(x, y, n_splits=3):\n",
        "    model = LogisticRegression(C=10, solver='sag', multi_class='multinomial', max_iter=300, n_jobs=-1)\n",
        "    i = 0\n",
        "    accuracies = []\n",
        "    kfold = KFold(n_splits)\n",
        "    for train_index, test_index in kfold.split(x):\n",
        "        classifier = LogisticRegression(C=10, solver='sag', multi_class='multinomial', max_iter=300, n_jobs=-1)\n",
        "        classifier.fit(x[train_index], y[train_index])\n",
        "        predictions = classifier.predict(x[test_index])\n",
        "        accuracies.append(accuracy_score(predictions, y[test_index]))\n",
        "        i += 1\n",
        "    average_accuracy = sum(accuracies) / len(accuracies)\n",
        "    return average_accuracy\n",
        "\n",
        "def run_experiment(preprocessor):\n",
        "    train = json.load(open('/kaggle/input/whats-cooking-kernels-only/train.json'))\n",
        "\n",
        "    target = [doc['cuisine'] for doc in train]\n",
        "    lb = LabelEncoder()\n",
        "    y = lb.fit_transform(target)\n",
        "\n",
        "    x = preprocessor.fit_transform(train)\n",
        "\n",
        "    return train_model(x, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8Jt-SwiLRtFf"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "results = []\n",
        "for (name, preprocessor) in [\n",
        "    ('TfidfVectorizer()', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(),\n",
        "    )),\n",
        "    ('TfidfVectorizer(binary=True)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(binary=True),\n",
        "    )),\n",
        "    ('TfidfVectorizer(min_df=3)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(min_df=3),\n",
        "    )),\n",
        "    ('TfidfVectorizer(min_df=5)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(min_df=5),\n",
        "    )),\n",
        "    ('TfidfVectorizer(max_df=0.95)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(max_df=0.95),\n",
        "    )),\n",
        "     ('TfidfVectorizer(max_df=0.9)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(max_df=0.9),\n",
        "    )),\n",
        "    ('TfidfVectorizer(sublinear_tf=True)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(sublinear_tf=True),\n",
        "    )),\n",
        "    ('TfidfVectorizer(strip_accents=unicode)', make_pipeline(\n",
        "        FunctionTransformer(lambda x: [\" \".join(doc['ingredients']).lower() for doc in x], validate=False),\n",
        "        TfidfVectorizer(strip_accents='unicode'),\n",
        "    )),\n",
        "]:\n",
        "    start = time.time()\n",
        "    accuracy = run_experiment(preprocessor)\n",
        "    execution_time = time.time() - start\n",
        "    results.append({\n",
        "        'name': name,\n",
        "        'accuracy': accuracy,\n",
        "        'execution time': f'{round(execution_time, 2)}s'\n",
        "    })\n",
        "pd.DataFrame(results, columns=['name', 'accuracy', 'execution time']).sort_values(by='accuracy', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I3zU0JsoRtFg"
      },
      "cell_type": "markdown",
      "source": [
        "So, We can see Tf-Idf is the Method suitable for our Data"
      ]
    },
    {
      "metadata": {
        "id": "uK7fgE54RtFg"
      },
      "cell_type": "markdown",
      "source": [
        "# Chapter 4:- The Final Decision"
      ]
    },
    {
      "metadata": {
        "id": "kwVfAmSFRtFh"
      },
      "cell_type": "markdown",
      "source": [
        "It's Time to build the model , first I will convert text data into numerical data using tfidf and then use SVC to build a model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DeiHl7_WRtFh"
      },
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(sublinear_tf=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GjkJrvmdRtFi"
      },
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.fit_transform(train['x'].values)\n",
        "X_train.sort_indices()\n",
        "X_test = vectorizer.transform(test['x'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0pFOpu-gRtFi"
      },
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "Y_train = label_encoder.fit_transform(train['cuisine'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RmbBxD3SRtFj"
      },
      "cell_type": "markdown",
      "source": [
        "I tried LogisticRegression, GaussianProcessClassifier, GradientBoostingClassifier, MLPClassifier, LGBMClassifier, SGDClassifier, Keras but SVC was working the best,So I choose SVC to build our final model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "A8DPmTHxRtFj"
      },
      "cell_type": "code",
      "source": [
        "classifier = SVC(C=100, # penalty parameter\n",
        "\t \t\t\t kernel='rbf', # kernel type, rbf working fine here\n",
        "\t \t\t\t degree=3, # default value\n",
        "\t \t\t\t gamma=1, # kernel coefficient\n",
        "\t \t\t\t coef0=1, # change to 1 from default value of 0.0\n",
        "\t \t\t\t shrinking=True, # using shrinking heuristics\n",
        "\t \t\t\t tol=0.001, # stopping criterion tolerance\n",
        "\t      \t\t probability=False, # no need to enable probability estimates\n",
        "\t      \t\t cache_size=200, # 200 MB cache size\n",
        "\t      \t\t class_weight=None, # all classes are treated equally\n",
        "\t      \t\t verbose=False, # print the logs\n",
        "\t      \t\t max_iter=-1, # no limit, let it run\n",
        "          \t\t decision_function_shape=None, # will use one vs rest explicitly\n",
        "          \t\t random_state=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "NH632asHRtFk"
      },
      "cell_type": "code",
      "source": [
        "model = OneVsRestClassifier(classifier, n_jobs=4)\n",
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "em55794_RtFk"
      },
      "cell_type": "code",
      "source": [
        "print (\"Predict on test data ... \")\n",
        "Y_test = model.predict(X_test)\n",
        "Y_pred = label_encoder.inverse_transform(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TJjqI4ulRtFl"
      },
      "cell_type": "code",
      "source": [
        "Y_pred[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wRDEJresRtFl"
      },
      "cell_type": "code",
      "source": [
        "test_id = test['id']\n",
        "sub = pd.DataFrame({'id': test_id, 'cuisine': Y_pred}, columns=['id', 'cuisine'])\n",
        "sub.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yKztHoIURtFl"
      },
      "cell_type": "code",
      "source": [
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LCbIDdw_RtFm"
      },
      "cell_type": "markdown",
      "source": [
        "This is My first kernel on kaggle. I have learnt a lot from this competition ,from the kaggle community and some exceptionally well written kernels.\n",
        "<br>The kernel By Rejasupotaro https://www.kaggle.com/rejasupotaro/representations-for-ingredients , helped me a lot and taught me how to compare all the Feature Engineering Techniques and choose the best one.\n",
        "<br>I wrote this kernel so that anyone starting with machine learning and natural language processing can understand it.\n",
        "### If you find my kernel useful and like it, please don't forget to upvote. Thank you!"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "AcHBsVAGRtFm"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "What's Cooking?",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}